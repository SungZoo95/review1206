# 오늘 배운거 정리
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer, accuracy_score

# Load the training data
# X_train, y_train = load_data()

# Create the model
modelx = XGBClassifier()

# Define the parameter grid to search
param_grid = {'max_depth': [3, 5, 7],
              'learning_rate': [0.1, 0.2, 0.3],
              'n_estimators': [50, 100, 200],
              'subsample': [0.5, 0.8, 1],
              'colsample_bytree': [0.5, 0.8, 1],
              'reg_alpha': [0, 0.1, 0.2],
              'reg_lambda': [0, 0.1, 0.2]}

# Define the scoring metric
accuracy_scorer = make_scorer(accuracy_score)

# Create the GridSearchCV object
grid_search = GridSearchCV(estimator=modelx, param_grid=param_grid, scoring=accuracy_scorer)

# Fit the GridSearchCV object to the training data
grid_search.fit(train_x, train_y)

# Print the best parameters and the best score
print(grid_search.best_params_)
print(grid_search.best_score_)

from xgboost import XGBClassifier

x_model =XGBClassifier(max_depth= 7,
                       learning_rate = 0.1,
                       n_estimators =50,
                       subsample = 0.8,
                       colsample_bytree= 0.5,
                       reg_alpha = 0.1,
                       reg_lambda = 0,
                       random_state =123)

x_model.fit(train_x, train_y)

pred = x_model.predict_proba(test_x)[:,1]

pred_label = np.where(pred>0.5,1 , 0)

submission =pd.DataFrame({'PassengerId':test['PassengerId'], 'Survived': pred_label})
submission.to_csv('submission0112_3.csv', index=False)

- 그리드서치로 최적의 파라미터를 찾아 점수를 높이는법을 배웠다
- 타이타닉은 XGB보다 SVC가 좋았기 때문에 SVC를 사용한다.
